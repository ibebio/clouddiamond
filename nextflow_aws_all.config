plugins {
    id 'nf-amazon'
}

params {

    // pipeline parameters
    // sra_accessions_list = "${projectDir}/data/demo/sra_acc_list_500.txt"
    // sra_accessions_list = "${projectDir}/data/demo/sra_accessions_list.txt"
    // the big one, 43k
    sra_accessions_list = "${projectDir}/data/demo/SraAccList_randomized_order.txt"
    // output
    outdir                     = './results'

}

//Indicate that we want to use awsbatch
process.executor = 'awsbatch'

// increase queue size, we want to run a lot of parallel jobs
//executor.queueSize = 5000
// 5000 caused I/O errors in bucket mounts in the vms when running convert2fastq, tune down:
executor.queueSize = 2500

//Indicate the name of the AWS Batch job queue that is configured in AWS Batch
process.queue = 'diamond-compute-queue'

//Name and version of the docker container we want to use within the Amazon ECS environment. //Users can optionally specify different docker containers for each process step
process.container = 'public.ecr.aws/amazonlinux/amazonlinux:latest'

//The AWS region where we want to run
aws.region = 'us-east-1'

//Important note!!! If we create a custom AMI for use with AWS Batch
//we need to specify the path to where the AWS cli tool is preinstalled
aws.batch.cliPath = '/home/ec2-user/micromamba/envs/base/bin/aws'

aws.batch.volumes = ['/data', '/s3mnt', '/home/ec2-user/sratoolkit.3.0.7-centos_linux64']

//Additionally, if we want to use S3 to hold intermediate files we can specify an S3 bucket and work directory preconfigured in S3
workDir = 's3://diamond2-bucket1/aws-cloud-align-20231208'


process {
  withLabel:process_low {
    cpus = {  1 * task.attempt }
    memory = {  4.GB * task.attempt }
    time = { 12.h * task.attempt }
  }
  withLabel:process_medium {
    cpus = { 2 * task.attempt }
    memory = { 7.GB * task.attempt }
    time = { 24.h * task.attempt }
  }
  withLabel:process_high {
    cpus = { 8 * task.attempt  }
    memory = { 14.GB * task.attempt }
    time = { 120.h * task.attempt }
  }

  //errorStrategy = 'retry'
  //maxRetries = 0
  // We want to push through with all accessions, even if some fail
  errorStrategy = 'ignore'
}
